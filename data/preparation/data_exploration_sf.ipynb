{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import scipy.sparse\n",
    "from collections import defaultdict\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pytz\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"Fire_Department_Calls_for_Service.csv\"\n",
    "station_path  = \"fire_base_stations.csv\"\n",
    "hospital_path  = \"hospitals_sfc.csv\"\n",
    "\n",
    "date_columns = [\"Dispatch DtTm\", \"Response DtTm\", \"On Scene DtTm\", \"Transport DtTm\", \"Hospital DtTm\", \"Available DtTm\", \"Received DtTm\"]\n",
    "dtm_format = \"%m/%d/%Y %I:%M:%S %p\"\n",
    "time_zone = pytz.timezone('America/Los_Angeles') #sf time zone is LA\n",
    "data = pd.read_csv(data_path, parse_dates=False, low_memory=False)\n",
    "\n",
    "\n",
    "for column in date_columns:\n",
    "    data[column] = pd.to_datetime(data[column], format=dtm_format, utc=True) #.dt.tz_localize(time_zone)\n",
    "\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load stations\n",
    "stations = pd.read_csv(station_path)\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#Hospitals\n",
    "Remove Seton and Kaiser SSF because these hospitals are outside of SF and the area where all the incidents happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#load hospitals\n",
    "hospitals_to_exclude = [\"Seton\", \"Kaiser SSF\"]\n",
    "hospitals = pd.read_csv(hospital_path)\n",
    "hospitals = hospitals[~hospitals[\"HospitalID\"].isin(hospitals_to_exclude)]\n",
    "hospitals = hospitals.reset_index()\n",
    "hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#bounding_box\n",
    "north_lat = 37.831666230626\n",
    "south_lat = 37.70825596126\n",
    "east_lon = -122.36147482652916\n",
    "west_lon = -122.513648358854\n",
    "#[37.70825596126, -122.513648358854] [37.831666230626, -122.36147482652916]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Things to filter:\n",
    "-Response DtTM not na\n",
    "-Unit Type medic\n",
    "\n",
    "Things which we ignore: private ambulances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data[~data[\"Response DtTm\"].isnull()]\n",
    "data = data[data[\"Unit Type\"] == \"MEDIC\"]\n",
    "data = data[~data[\"Zipcode of Incident\"].isnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data[(data[\"Response DtTm\"].dt.year >= 2001) & (data[\"Response DtTm\"].dt.year <= 2021)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Filter out incidents that do not follow a logical time order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data[~(data[\"Response DtTm\"]>data[\"On Scene DtTm\"])]\n",
    "data = data[~(data[\"On Scene DtTm\"] > data[\"Transport DtTm\"])]\n",
    "data = data[~(data[\"Transport DtTm\"] > data[\"Hospital DtTm\"])]\n",
    "data = data[~(data[\"Hospital DtTm\"] > data[\"Available DtTm\"])]\n",
    "data = data[~(data[\"Response DtTm\"] > data[\"Available DtTm\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"lon\"] = data[\"case_location\"].str.replace(\"POINT (\", \"\", regex=False).str.replace(\")\", \"\", regex=False).str.split(\" \").str.get(0).astype(float)\n",
    "data[\"lat\"] = data[\"case_location\"].str.replace(\"POINT (\", \"\", regex=False).str.replace(\")\", \"\", regex=False).str.split(\" \").str.get(1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data[~(data[\"lat\"].isnull() | data[\"lon\"].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"seconds_to_incident\"] = (data[\"On Scene DtTm\"] - data[\"Response DtTm\"]).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"seconds_at_incident\"] = (data[\"Transport DtTm\"] - data[\"On Scene DtTm\"]).dt.total_seconds()\n",
    "data[\"seconds_to_hospital\"] = (data[\"Hospital DtTm\"] - data[\"Transport DtTm\"]).dt.total_seconds()\n",
    "data[\"seconds_hospital_to_available\"] = (data[\"Available DtTm\"] - data[\"Hospital DtTm\"]).dt.total_seconds()\n",
    "data[\"patient_went_to_hospital\"] = ~data[\"Transport DtTm\"].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Neighborhooods - Analysis Boundaries\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"Call Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[data[\"Call Type\"] == \"Aircraft Emergency\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[data[\"Neighborhooods - Analysis Boundaries\"] == \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"total_emergency_time_seconds\"] = (data[\"Available DtTm\"] - data[\"Response DtTm\"]).dt.total_seconds()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"month\"] = data[\"Response DtTm\"].dt.month\n",
    "incidents_per_month = data.groupby(\"month\").size().reset_index(name=\"count\")\n",
    "incidents_per_month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=incidents_per_month, x=\"month\", y=\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"minute_of_day\"] = (\n",
    "            (data[\"Response DtTm\"] - data[\"Response DtTm\"].dt.normalize()) / pd.Timedelta(\"15 minute\")).astype(int)\n",
    "incidents_per_minute = data.groupby([\"minute_of_day\",\n",
    "                                     data[\"Response DtTm\"].dt.day_of_year]).size().reset_index(name=\"count\")\n",
    "sns.lineplot(data=incidents_per_minute, x=\"minute_of_day\", y=\"count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[\"day_of_week\"] = data[\"Response DtTm\"].dt.day_of_week\n",
    "incidents_per_minute = data.groupby([\"day_of_week\",\n",
    "                                     data[\"Response DtTm\"].dt.isocalendar().week]).size().reset_index(name=\"count\")\n",
    "sns.barplot(data=incidents_per_minute, x=\"day_of_week\", y=\"count\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Find out bounding box of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_long = data[\"lon\"].min()\n",
    "max_long = data[\"lon\"].max()\n",
    "min_lat = data[\"lat\"].min()\n",
    "max_lat = data[\"lat\"].max()\n",
    "\n",
    "print([min_lat, min_long],[max_lat,max_long])\n",
    "\n",
    "m = folium.Map()\n",
    "m.fit_bounds([[min_lat, min_long],[max_lat,max_long]])\n",
    "#folium.LayerControl().add_to(m)\n",
    "folium.TileLayer('openstreetmap').add_to(m)\n",
    "m\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "incidents_fg = folium.map.FeatureGroup(name=\"Incidents\")\n",
    "plugins.FastMarkerCluster(data[[\"lat\", \"lon\"]]).add_to(incidents_fg)\n",
    "m.add_child(incidents_fg)\n",
    "\n",
    "hospitals_fg = folium.map.FeatureGroup(name=\"Hospitals\")\n",
    "for _, row in hospitals.iterrows():\n",
    "    hospitals_fg.add_child(folium.CircleMarker(location=[row[\"latitude\"], row[\"longitude\"]], color=\"red\"))\n",
    "m.add_child(hospitals_fg)\n",
    "\n",
    "stations_fg = folium.map.FeatureGroup(name=\"Stations\")\n",
    "for _, row in stations.iterrows():\n",
    "    stations_fg.add_child(folium.CircleMarker(location=[row[\"lat\"], row[\"lon\"]]))\n",
    "m.add_child(stations_fg)\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "incidents_per_point = data.groupby([\"lat\", \"lon\"]).size().sort_values(ascending=False) .reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "heatmap_fg = folium.map.FeatureGroup(name=\"heatmap\")\n",
    "plugins.HeatMap(incidents_per_point).add_to(heatmap_fg)\n",
    "m.add_child(heatmap_fg)\n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "m.add_child(folium.LayerControl())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_stored_graph = True\n",
    "\n",
    "if not use_stored_graph:\n",
    "    #network_type = \"drive_service\"\n",
    "    network_type = \"drive\"\n",
    "    graph = ox.graph_from_bbox(north=north_lat,\n",
    "                               south=south_lat,\n",
    "                               east=east_lon,\n",
    "                               west=west_lon,\n",
    "                               network_type=network_type)\n",
    "    graph = ox.speed.add_edge_speeds(graph)\n",
    "    graph = ox.speed.add_edge_travel_times(graph)\n",
    "    #ox.basic_stats(graph)\n",
    "\n",
    "if not use_stored_graph:\n",
    "    edges_before_strong = len(graph.edges())\n",
    "    nodes_before_strong = len(graph.nodes())\n",
    "    largest_comp = max(nx.strongly_connected_components(graph), key=len)\n",
    "    graph = graph.subgraph(largest_comp).copy()\n",
    "\n",
    "    edges_after_strong = len(graph.edges())\n",
    "    nodes_after_strong = len(graph.nodes())\n",
    "    print(edges_before_strong - edges_after_strong)\n",
    "    print(nodes_before_strong - nodes_after_strong)\n",
    "\n",
    "    if not use_stored_graph:\n",
    "        osmids = list(graph.nodes)\n",
    "        graph = nx.relabel.convert_node_labels_to_integers(graph)\n",
    "\n",
    "        # give each node its original osmid as attribute since we relabeled them\n",
    "        osmid_values = {k: v for k, v in zip(graph.nodes, osmids)}\n",
    "        nx.set_node_attributes(graph, osmid_values, \"osmid\")\n",
    "\n",
    "\n",
    "if not use_stored_graph:\n",
    "    ox.save_graphml(graph, \"sf/graph.gz\")\n",
    "else:\n",
    "    graph = ox.load_graphml(\"sf/graph.gz\")\n",
    "    osmids = list(graph.nodes)\n",
    "\n",
    "# convert networkx graph to igraph\n",
    "G_ig = ig.Graph(directed=True)\n",
    "G_ig.add_vertices(graph.nodes)\n",
    "G_ig.add_edges(graph.edges())\n",
    "G_ig.vs[\"osmid\"] = osmids\n",
    "G_ig.es[\"travel_time\"] = list(nx.get_edge_attributes(graph, \"travel_time\").values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nearest_nodes_stations = ox.nearest_nodes(graph, stations[\"lon\"], stations[\"lat\"])\n",
    "nearest_nodes_incidents = ox.nearest_nodes(graph, data[\"lon\"], data[\"lat\"])\n",
    "nearest_nodes_hospitals = ox.nearest_nodes(graph, hospitals[\"longitude\"], hospitals[\"latitude\"])\n",
    "\n",
    "stations[\"nearest_node\"] = nearest_nodes_stations\n",
    "data[\"nearest_node\"] = nearest_nodes_incidents\n",
    "hospitals[\"nearest_node\"] = nearest_nodes_hospitals\n",
    "\n",
    "#data[\"position_in_matrix\"] = data.index\n",
    "stations[\"position_in_matrix\"] = stations.index\n",
    "hospitals[\"position_in_matrix\"] = hospitals.index\n",
    "\n",
    "assert len(hospitals[hospitals.duplicated(subset=[\"nearest_node\"], keep=False)]) == 0\n",
    "assert len(stations[stations.duplicated(subset=[\"nearest_node\"], keep=False)]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unique_incident_nodes = np.array(nearest_nodes_incidents)\n",
    "unique_incident_nodes = np.unique(unique_incident_nodes)\n",
    "unique_incident_nodes_df = pd.DataFrame()\n",
    "unique_incident_nodes_df[\"nearest_node_unique\"] = unique_incident_nodes\n",
    "unique_incident_nodes_df[\"position_in_matrix\"] = unique_incident_nodes_df.index\n",
    "\n",
    "#data = data.merge(unique_incident_nodes_df, left_on=\"nearest_node\", right_on=\"nearest_node_unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "station_to_incident = np.array(G_ig.shortest_paths(source=nearest_nodes_stations, target=unique_incident_nodes, weights=\"travel_time\"))\n",
    "incident_to_hospitals = np.array(G_ig.shortest_paths(source=unique_incident_nodes, target=nearest_nodes_hospitals, weights=\"travel_time\"))\n",
    "incident_to_station = np.array(G_ig.shortest_paths(source=unique_incident_nodes,\n",
    "                                                  target=nearest_nodes_stations,\n",
    "                                                  weights=\"travel_time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hospital_to_station = np.array(G_ig.shortest_paths(source=nearest_nodes_hospitals,\n",
    "                                                   target=nearest_nodes_stations,\n",
    "                                                   weights=\"travel_time\"))\n",
    "station_to_station = np.array(G_ig.shortest_paths(source=nearest_nodes_stations,\n",
    "                                                  target=nearest_nodes_stations,\n",
    "                                                  weights=\"travel_time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#find the closest station for each incident\n",
    "\n",
    "#format station_to_incident : index of node to index of node\n",
    "closest_station = station_to_incident.argmin(axis=0)\n",
    "unique_incident_nodes_df[\"closest_station_index\"] = closest_station\n",
    "data = data.merge(unique_incident_nodes_df, left_on=\"nearest_node\", right_on=\"nearest_node_unique\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Split data\n",
    "Train = 2001-2019\n",
    "Validation = 2020\n",
    "Test = 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validation_data = data[data[\"Response DtTm\"].dt.year == 2020]\n",
    "test_data = data[data[\"Response DtTm\"].dt.year == 2021]\n",
    "train_data = data[(data[\"Response DtTm\"].dt.year >= 2001) & (data[\"Response DtTm\"].dt.year <= 2019)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.groupby(data[\"Response DtTm\"].dt.year).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"processed\"\n",
    "\n",
    "#export travel times\n",
    "np.savez(f\"{data_path}/station_to_incident\",station_to_incident)\n",
    "np.savez(f\"{data_path}/incident_to_station\",incident_to_station)\n",
    "np.savez(f\"{data_path}/incident_to_hospitals\",incident_to_hospitals)\n",
    "np.savez(f\"{data_path}/hospital_to_station\",hospital_to_station)\n",
    "np.savez(f\"{data_path}/station_to_station\", station_to_station)\n",
    "\n",
    "\n",
    "#time format int, seconds since midnight\n",
    "#position in distance matrix\n",
    "#day of year\n",
    "\n",
    "def create_export_frame(base_df):\n",
    "    data_export = pd.DataFrame()\n",
    "    data_export[\"IncidentTime\"] = ((\n",
    "                (base_df[\"Response DtTm\"] - base_df[\"Response DtTm\"].dt.normalize()) / pd.Timedelta(\"1s\")).astype(int)) + (base_df[\"Response DtTm\"].dt.day_of_year * 24*60*60)\n",
    "    data_export[\"DayOfYear\"] = base_df[\"Response DtTm\"].dt.day_of_year\n",
    "    data_export[\"PositionInDistanceMatrix\"] = base_df[\"position_in_matrix_x\"]\n",
    "    data_export[\"DemandLocationID\"] = base_df[\"closest_station_index\"]\n",
    "    data_export[\"Month\"] = base_df[\"Response DtTm\"].dt.month\n",
    "    data_export[\"WeekDay\"] = base_df[\"Response DtTm\"].dt.day_of_week\n",
    "    data_export[\"Year\"] = base_df[\"Response DtTm\"].dt.year\n",
    "    data_export[\"EpisodeGroup\"] = base_df[\"Response DtTm\"].dt.year\n",
    "    data_export[\"Lon\"] = base_df[\"lon\"]\n",
    "    data_export[\"Lat\"] = base_df[\"lat\"]\n",
    "    data_export[\"Priority\"] = base_df[\"Final Priority\"]\n",
    "    data_export[\"TransportToHospital\"] = base_df[\"patient_went_to_hospital\"]\n",
    "    data_export[\"SecondsAtIncident\"] = base_df[\"seconds_at_incident\"]\n",
    "    data_export[\"TotalEmergencyTime\"] = base_df[\"total_emergency_time_seconds\"]\n",
    "    data_export[\"TimeAtHospital\"] = base_df[\"seconds_hospital_to_available\"]\n",
    "    return data_export\n",
    "\n",
    "\n",
    "def create_episode_groups(base_df):\n",
    "    years = base_df[\"Response DtTm\"].dt.year.unique()\n",
    "\n",
    "    data_export = pd.DataFrame()\n",
    "    data_export[\"EpisodeGroup\"] = years\n",
    "\n",
    "    data_export[\"MaxTime\"] = [(base_df[base_df[\"Response DtTm\"].dt.year == year][\"Response DtTm\"].dt.day_of_year.max() + 1) * 24*60*60 for year in years]\n",
    "\n",
    "    return data_export\n",
    "\n",
    "\n",
    "train_export = create_export_frame(train_data)\n",
    "val_export = create_export_frame(validation_data)\n",
    "test_export = create_export_frame(test_data)\n",
    "\n",
    "train_export.to_csv(f\"{data_path}/train.csv\")\n",
    "val_export.to_csv(f\"{data_path}/val.csv\")\n",
    "test_export.to_csv(f\"{data_path}/test.csv\")\n",
    "\n",
    "create_episode_groups(train_data).to_csv(f\"{data_path}/episode_groups_train.csv\")\n",
    "create_episode_groups(validation_data).to_csv(f\"{data_path}/episode_groups_val.csv\")\n",
    "create_episode_groups(test_data).to_csv(f\"{data_path}/episode_groups_test.csv\")\n",
    "\n",
    "\n",
    "hospital_export = pd.DataFrame()\n",
    "hospital_export[\"Name\"] = hospitals[\"HospitalID\"]\n",
    "hospital_export[\"PositionInDistanceMatrix\"] = hospitals[\"position_in_matrix\"]\n",
    "hospital_export[\"Lon\"] = hospitals[\"longitude\"]\n",
    "hospital_export[\"Lat\"] = hospitals[\"latitude\"]\n",
    "hospital_export.to_csv(f\"{data_path}/hospitals.csv\")\n",
    "\n",
    "\n",
    "station_export = pd.DataFrame()\n",
    "station_export[\"Name\"] = stations[\"name\"]\n",
    "station_export[\"PositionInDistanceMatrix\"] = stations[\"position_in_matrix\"]\n",
    "station_export[\"Lon\"] = stations[\"lon\"]\n",
    "station_export[\"Lat\"] = stations[\"lat\"]\n",
    "station_export.to_csv(f\"{data_path}/stations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count_per_station = validation_data.groupby(\"closest_station_index\").size().reset_index(name=\"count\")\n",
    "total = len(validation_data)\n",
    "count_per_station[\"fraction\"] = count_per_station[\"count\"]/total\n",
    "\n",
    "count_per_station.to_csv(f\"{data_path}/demand_weights.csv\")\n",
    "\n",
    "count_per_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# number of incidents per hour\n",
    "# we should only do this on the validation set\n",
    "validation_data[\"time\"] = pd.DatetimeIndex(validation_data[\"Response DtTm\"])\n",
    "validation_data = validation_data.set_index(\"time\")\n",
    "\n",
    "incidents_per_hour_and_demand_location = validation_data.groupby(\"closest_station_index\").resample(\"60min\").size().reset_index(\n",
    "    name=\"count\")\n",
    "\n",
    "average_number_of_incidents_per_hour_per_station = incidents_per_hour_and_demand_location.groupby(\n",
    "        \"closest_station_index\").mean()\n",
    "\n",
    "average_number_of_incidents_per_hour_per_station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "demand_forcast = incidents_per_hour_and_demand_location.groupby([\"closest_station_index\",\n",
    "                                                                 incidents_per_hour_and_demand_location.time.dt.hour]).mean()\n",
    "demand_forcast = demand_forcast.to_numpy().reshape(len(stations), 24)\n",
    "np.savez(f\"{data_path}/average_hourly_demand\", demand_forcast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[(data[\"seconds_hospital_to_available\"]>0) & ~data[\"Hospital DtTm\"].isna()][\"seconds_hospital_to_available\"].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
